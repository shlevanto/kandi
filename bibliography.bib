
@article{ramsahai_connecting_2020,
	title = {Connecting actuarial judgment to probabilistic learning techniques with graph theory},
	doi = {10.48550/arXiv.2007.15475},
	abstract = {Graphical models have been widely used in applications ranging from medical expert systems to natural language processing. Their popularity partly arises since they are intuitive representations of complex inter-dependencies among variables with efficient algorithms for performing computationally intensive inference in high-dimensional models. It is argued that the formalism is very useful for applications in the modelling of non-life insurance claims data. It is also shown that actuarial models in current practice can be expressed graphically to exploit the advantages of the approach. More general models are proposed within the framework to demonstrate the potential use of graphical models for probabilistic learning with telematics and other dynamic actuarial data. The discussion also demonstrates throughout that the intuitive nature of the models allows the inclusion of qualitative knowledge or actuarial judgment in analyses.},
	journaltitle = {arXiv:2007.15475 [cs.AI]},
	author = {Ramsahai, Roland R.},
	date = {2020},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Quantitative Finance - Statistical Finance, Statistics - Applications},
}

@book{myllymaki_bayes-verkkojen_1998,
	location = {Helsinki},
	title = {Bayes-verkkojen mahdollisuudet},
	volume = {58},
	isbn = {951-53-1391-0},
	publisher = {Tekes},
	location = {Helsinki},
	series = {Teknologiakatsaus},
	author = {Myllymäki, Petri and Tirri, Henry},
	date = {1998},
	file = {bvmahd.pdf:C\:\\Users\\LEVANSI\\Zotero\\storage\\YZ27W5DV\\bvmahd.pdf:application/pdf},
}

@article{jordan_graphical_2004,
	title = {Graphical Models},
	volume = {19},
	issn = {0883-4237},
	doi = {10.1214/088342304000000026},
	abstract = {Statistical applications in fields such as bioinformatics, information retrieval, speech processing, image processing and communications often involve large-scale models in which thousands or millions of random variables are linked in complex ways. Graphical models provide a general methodology for approaching these problems, and indeed many of the models developed by researchers in these applied fields are instances of the general graphical model formalism. We review some of the basic ideas underlying graphical models, including the algorithmic ideas that allow graphical models to be deployed in large-scale data analysis problems. We also present examples of graphical models in bioinformatics, error-control coding and language processing.},
	pages = {140--155},
	number = {1},
	journaltitle = {Statistical Science},
	author = {Jordan, Michael I.},
	date = {2004},
	note = {Publisher: Institute of Mathematical Statistics},
	file = {JSTOR Full Text PDF:C\:\\Users\\LEVANSI\\Zotero\\storage\\KMF4INY3\\Jordan - 2004 - Graphical Models.pdf:application/pdf},
}

@article{scanagatta_survey_2019,
	title = {A survey on Bayesian network structure learning from data},
	volume = {8},
	issn = {2192-6360},
	doi = {10.1007/s13748-019-00194-y},
	abstract = {A necessary step in the development of artificial intelligence is to enable a machine to represent how the world works, building an internal structure from data. This structure should hold a good trade-off between expressive power and querying efficiency. Bayesian networks have proven to be an effective and versatile tool for the task at hand. They have been applied to modeling knowledge in a variety of fields, ranging from bioinformatics to law, from image processing to economic risk analysis. A crucial aspect is learning the dependency graph of a Bayesian network from data. This task, called structure learning, is {NP}-hard and is the subject of intense, cutting-edge research. In short, it can be thought of as choosing one graph over the many candidates, grounding our reasoning over a collection of samples of the distribution generating the data. The number of possible graphs increases very quickly at the increase in the number of variables. Searching in this space, and selecting a graph over the others, becomes quickly burdensome. In this survey, we review the most relevant structure learning algorithms that have been proposed in the literature. We classify them according to the approach they follow for solving the problem and we also show alternatives for handling missing data and continuous variable. An extensive review of existing software tools is also given.},
	pages = {425--439},
	number = {4},
	journaltitle = {Progress in Artificial Intelligence},
	shortjournal = {Prog Artif Intell},
	author = {Scanagatta, Mauro and Salmerón, Antonio and Stella, Fabio},
	date = {2019},
	langid = {english},
	keywords = {Machine learning, Statistics, Bayesian network, Structure learning},
	file = {Full Text PDF:C\:\\Users\\LEVANSI\\Zotero\\storage\\2424TA3A\\Scanagatta et al. - 2019 - A survey on Bayesian network structure learning fr.pdf:application/pdf},
}

@inproceedings{mittal_review_2011,
	title = {A review of some Bayesian Belief Network structure learning algorithms},
	doi = {10.1109/ICICS.2011.6173579},
	abstract = {Bayesian Belief Networks ({BBNs}) are useful in modeling complex situations. Such graphical models help in giving better insight and understanding of the situation. Many algorithms for machine learning of {BBN} structures have been developed. In this paper six different algorithms have been reviewed by constructing {BBN} structures for two different datasets using various algorithms. Some inferences have been drawn from the results obtained from the study which may help in decision making.},
	eventtitle = {2011 8th International Conference on Information, Communications \& Signal Processing},
	pages = {1--5},
	booktitle = {2011 8th International Conference on Information, Communications \& Signal Processing},
	author = {Mittal, Sangeeta and Maskara, S. L.},
	date = {2011},
	keywords = {Diseases, Bayesian Belief Network, Bayesian methods, Hepatitis Domain Diseases, Inference algorithms, Learning systems, Machine learning algorithms, Size measurement, Structure Learning, Urinary System Diseases},
}

@article{malone_empirical_2018,
	title = {Empirical hardness of finding optimal Bayesian network structures: algorithm selection and runtime prediction},
	volume = {107},
	issn = {1573-0565},
	doi = {10.1007/s10994-017-5680-2},
	shorttitle = {Empirical hardness of finding optimal Bayesian network structures},
	abstract = {Various algorithms have been proposed for finding a Bayesian network structure that is guaranteed to maximize a given scoring function. Implementations of state-of-the-art algorithms, solvers, for this Bayesian network structure learning problem rely on adaptive search strategies, such as branch-and-bound and integer linear programming techniques. Thus, the time requirements of the solvers are not well characterized by simple functions of the instance size. Furthermore, no single solver dominates the others in speed. Given a problem instance, it is thus a priori unclear which solver will perform best and how fast it will solve the instance. We show that for a given solver the hardness of a problem instance can be efficiently predicted based on a collection of non-trivial features which go beyond the basic parameters of instance size. Specifically, we train and test statistical models on empirical data, based on the largest evaluation of state-of-the-art exact solvers to date. We demonstrate that we can predict the runtimes to a reasonable degree of accuracy. These predictions enable effective selection of solvers that perform well in terms of runtimes on a particular instance. Thus, this work contributes a highly efficient portfolio solver that makes use of several individual solvers.},
	pages = {247--283},
	number = {1},
	journaltitle = {Machine Learning},
	shortjournal = {Mach Learn},
	author = {Malone, Brandon and Kangas, Kustaa and Järvisalo, Matti and Koivisto, Mikko and Myllymäki, Petri},
	date = {2018},
	langid = {english},
	keywords = {Bayesian networks, Structure learning, Algorithm portfolio, Algorithm selection, Empirical hardness, Hyperparameter optimization, Runtime prediction},
}

@article{chickering_large-sample_2004,
	title = {Large-Sample Learning of Bayesian Networks is {NP}-Hard},
	volume = {5},
	issn = {1532-4435},
	abstract = {In this paper, we provide new complexity results for algorithms that learn discrete-variable Bayesian networks from data. Our results apply whenever the learning algorithm uses a scoring criterion that favors the simplest structure for which the model is able to represent the generative distribution exactly. Our results therefore hold whenever the learning algorithm uses a consistent scoring criterion and is applied to a sufficiently large dataset. We show that identifying high-scoring structures is {NP}-hard, even when any combination of one or more of the following hold: the generative distribution is perfect with respect to some {DAG} containing hidden variables; we are given an independence oracle; we are given an inference oracle; we are given an information oracle; we restrict potential solutions to structures in which each node has at most k parents, for all k{\textgreater}=3.Our proof relies on a new technical result that we establish in the appendices. In particular, we provide a method for constructing the local distributions in a Bayesian network such that the resulting joint distribution is provably perfect with respect to the structure of the network.},
	pages = {1287--1330},
	journaltitle = {The Journal of Machine Learning Research},
	shortjournal = {J. Mach. Learn. Res.},
	author = {Chickering, David Maxwell and Heckerman, David and Meek, Christopher},
	date = {2004},
}

@incollection{ruggeri_bayesian_2008,
	location = {Chichester, {UK}},
	title = {Bayesian Networks},
	pages = {eqr089},
	booktitle = {Encyclopedia of Statistics in Quality and Reliability},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Ben-Gal, Irad},
	editor = {Ruggeri, Fabrizio and Kenett, Ron S. and Faltin, Frederick W.},
	urldate = {2022-09-19},
	date = {2008},
	langid = {english},
	doi = {10.1002/9780470061572.eqr089},
}

@article{scutari_learning_2010,
	title = {Learning Bayesian networks with the bnlearn R package},
	issn = {1548-7660},
	volume = {35},
	pages = {1--22},
	number = {3},
	journaltitle = {Journal of Statistical Software},
	author = {Scutari, Marco},
	date = {2010},
	file = {0908.3817.pdf:C\:\\Users\\LEVANSI\\Zotero\\storage\\G9V6RDQ9\\0908.3817.pdf:application/pdf},
}

@book{diestel_graph_2017,
	location = {New York, {NY}},
	title = {Graph theory},
	isbn = {978-3-662-53621-6},
	publisher = {Springer Berlin Heidelberg},
	author = {Diestel, Reinhard},
	date = {2017},
}

@book{dasgupta_probability_2011,
	location = {New York},
	title = {Probability for statistics and machine learning: fundamentals and advanced topics},
	isbn = {9781441996343},
	series = {Springer texts in statistics},
	shorttitle = {Probability for statistics and machine learning},
	pagetotal = {782},
	publisher = {Springer},
	author = {{DasGupta}, Anirban},
	date = {2011},
	keywords = {Machine learning, Mathematical statistics, Probabilities, Stochastic processes},
}


@article{karolaakso_socioeconomic_2020,
	title = {Socioeconomic factors in disability retirement due to mental disorders in Finland},
	doi = {10.1093/eurpub/ckaa132},
	journaltitle = {European Journal of Public Health},
	shortjournal = {Eur J Public Health},
	author = {Karolaakso, Tino and Autio, Reija and Näppilä, Turkka and Nurmela, Kirsti and Pirkola, Sami},
	date = {2020},
	langid = {english},
}

@article{karolaakso_contextual_2021,
	title = {Contextual and mental health service factors in mental disorder-based disability pensioning in Finland – a regional comparison},
	volume = {21},
	issn = {1472-6963},
	doi = {10.1186/s12913-021-07099-4},
	pages = {1081},
	number = {1},
	journaltitle = {{BMC} Health Services Research},
	shortjournal = {{BMC} Health Services Research},
	author = {Karolaakso, Tino and Autio, Reija and Näppilä, Turkka and Leppänen, Helena and Rissanen, Päivi and Tuomisto, Martti T. and Karvonen, Sakari and Pirkola, Sami},
	date = {2021},
	keywords = {Compositional factor, Contextual factor, Disability pension, Mental disorders, Mental health services, Regional differences},
}

@software{bayesnetsjl_2021,
	title = {{BayesNets}.jl},
	url = {https://github.com/sisl/BayesNets.jl},
	publisher = {Stanford Intelligent Systems Laboratory},
	date = {2022-07-06},
	urldate = {2021-10-17},
}

@article{pearl_fusion_1986,
	title = {Fusion, propagation, and structuring in belief networks},
	volume = {29},
	issn = {00043702},
	doi = {10.1016/0004-3702(86)90072-X},
	pages = {241--288},
	number = {3},
	journaltitle = {Artificial Intelligence},
	shortjournal = {Artificial Intelligence},
	author = {Pearl, Judea},
	date = {1986},
	langid = {english},
}


@inproceedings{zhang_brief_2019,
	title = {A brief review of Bayesian belief network},
	doi = {10.1109/CCDC.2019.8832649},
	eventtitle = {2019 Chinese Control And Decision Conference ({CCDC})},
	pages = {3910--3914},
	booktitle = {2019 Chinese Control And Decision Conference ({CCDC})},
	author = {Zhang, Jinqing and Yue, Haosong and Wu, Xingming and Chen, Weihai},
	date = {2019},
	note = {{ISSN}: 1948-9447},
	keywords = {Bayes methods, Bayesian belief network, Fault diagnosis, Peer-to-peer computing, Probabilistic logic, Training, fault diagnosis, reliability analysis, structure learning},
}


@article{kaur_review_2013,
	title = {A Review of Machine Learning based Anomaly Detection Techniques},
	volume = {2},
	issn = {23198656},
	doi = {10.7753/IJCATR0202.1020},
	pages = {185--187},
	number = {2},
	journaltitle = {International Journal of Computer Applications Technology and Research},
	shortjournal = {{IJCATR}},
	author = {Kaur, Harjinder and Singh, Gurpreet and Minhas, Jaspreet},
	date = {2013},
	file = {Full Text:/home/levantsi/Zotero/storage/MWXKWKP9/Kaur et al. - 2013 - A Review of Machine Learning based Anomaly Detecti.pdf:application/pdf},
}

@article{vowels_dya_2022,
	title = {D’ya Like {DAGs}? A Survey on Structure Learning and Causal Discovery},
	issn = {0360-0300},
	doi = {10.1145/3527154},
	shorttitle = {D’ya Like {DAGs}?},
	abstract = {Causal reasoning is a crucial part of science and human intelligence. In order to discover causal relationships from data, we need structure discovery methods. We provide a review of background theory and a survey of methods for structure discovery. We primarily focus on modern, continuous optimization methods, and provide reference to further resources such as benchmark datasets and software packages. Finally, we discuss the assumptive leap required to take us from structure to causality.},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Vowels, Matthew J. and Camgoz, Necati Cihan and Bowden, Richard},
	date = {2022},
	file = {Full Text PDF:/home/levantsi/Zotero/storage/NYC7L4DJ/Vowels et al. - 2022 - D’ya Like DAGs A Survey on Structure Learning and.pdf:application/pdf},
}

@article{behjati_improved_2020,
	title = {Improved K2 algorithm for Bayesian network structure learning},
	volume = {91},
	issn = {0952-1976},
	url = {https://www.sciencedirect.com/science/article/pii/S095219762030083X},
	doi = {10.1016/j.engappai.2020.103617},
	pages = {103617},
	journaltitle = {Engineering Applications of Artificial Intelligence},
	shortjournal = {Engineering Applications of Artificial Intelligence},
	author = {Behjati, Shahab and Beigy, Hamid},
	date = {2020},
	langid = {english},
	keywords = {Bayesian network, Constraint-based algorithm, Score-based algorithms, Structure learning},
	file = {ScienceDirect Full Text PDF:/home/levantsi/Zotero/storage/55CPRZJ9/Behjati and Beigy - 2020 - Improved K2 algorithm for Bayesian network structu.pdf:application/pdf;ScienceDirect Snapshot:/home/levantsi/Zotero/storage/BSKCJ6BB/S095219762030083X.html:text/html},
}
@article{atienza_pybnesian_2022,
	title = {{PyBNesian}: An extensible python package for Bayesian networks},
	volume = {504},
	issn = {0925-2312},
	doi = {10.1016/j.neucom.2022.06.112},
	shorttitle = {{PyBNesian}},
	pages = {204--209},
	journaltitle = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Atienza, David and Bielza, Concha and Larrañaga, Pedro},
	date = {2022},
	langid = {english},
	keywords = {Bayesian networks, Conditional independence, Dynamic models, Kernel density estimation},
	file = {Full Text:/home/levantsi/Zotero/storage/UFK8EJ73/Atienza et al. - 2022 - PyBNesian An extensible python package for Bayesi.pdf:application/pdf;ScienceDirect Snapshot:/home/levantsi/Zotero/storage/RTA9KCB6/S0925231222008438.html:text/html},
}


@article{liu_empirical_2012,
	title = {Empirical evaluation of scoring functions for Bayesian network model selection},
	volume = {13},
	issn = {1471-2105},
	doi = {10.1186/1471-2105-13-S15-S14},
	pages = {S14},
	issue = {Suppl 15},
	journaltitle = {{BMC} Bioinformatics},
	shortjournal = {{BMC} Bioinformatics},
	author = {Liu, Zhifa and Malone, Brandon and Yuan, Changhe},
	date = {2012},
}

@article{gross_machine_2020,
	title = {Machine Learning for Work Disability Prevention: Introduction to the Special Series},
	volume = {30},
	issn = {1573-3688},
	doi = {10.1007/s10926-020-09910-1},
	shorttitle = {Machine Learning for Work Disability Prevention},
	pages = {303--307},
	number = {3},
	journaltitle = {Journal of Occupational Rehabilitation},
	shortjournal = {J Occup Rehabil},
	author = {Gross, Douglas P. and Steenstra, Ivan A. and Harrell, Frank E. and Bellinger, Colin and Zaïane, Osmar},
	date = {2020},
	langid = {english},
	file = {Springer Full Text PDF:/home/levantsi/Zotero/storage/UN6BZSZ4/Gross et al. - 2020 - Machine Learning for Work Disability Prevention I.pdf:application/pdf},
}

@article{li_hybrid_2018,
	title = {A Hybrid Structure Learning Algorithm for Bayesian Network Using Experts’ Knowledge},
	volume = {20},
	issn = {1099-4300},
	doi = {10.3390/e20080620},
	pages = {620},
	number = {8},
	journaltitle = {Entropy},
	author = {Li, Hongru and Guo, Huiping},
	date = {2018},
	langid = {english},
}


@article{schwarz_estimating_1978,
	title = {Estimating the Dimension of a Model},
	volume = {6},
	issn = {0090-5364, 2168-8966},
	doi = {10.1214/aos/1176344136},
	pages = {461--464},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Schwarz, Gideon},
	date = {1978},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62F99, 62J99, Akaike information criterion, asymptotics, dimension},
	file = {Full Text PDF:/home/levantsi/Zotero/storage/GHNCI3QI/Schwarz - 1978 - Estimating the Dimension of a Model.pdf:application/pdf;Snapshot:/home/levantsi/Zotero/storage/6TLDSZSB/1176344136.html:text/html},
}


@article{bartlett_integer_2017,
	title = {Integer Linear Programming for the Bayesian network structure learning problem},
	volume = {244},
	issn = {0004-3702},
	doi = {10.1016/j.artint.2015.03.003},
	series = {Combining Constraint Solving with Mining and Learning},
	pages = {258--271},
	journaltitle = {Artificial Intelligence},
	shortjournal = {Artificial Intelligence},
	author = {Bartlett, Mark and Cussens, James},
	date = {2017},
	langid = {english},
	keywords = {Bayesian networks, Constrained optimisation, Cutting planes, Integer Linear Programming, Separation},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\LEVANSI\\Zotero\\storage\\PU3NG4ZA\\Bartlett and Cussens - 2017 - Integer Linear Programming for the Bayesian networ.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\LEVANSI\\Zotero\\storage\\5XPF65VH\\S0004370215000417.html:text/html},
}

@article{rissanen_stochastic_1987,
	title = {Stochastic Complexity},
	volume = {49},
	issn = {2517-6161},
	doi = {10.1111/j.2517-6161.1987.tb01694.x},
	pages = {223--239},
	number = {3},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Rissanen, Jorma},
	date = {1987},
	langid = {english},
}

@article{friedman_greedy_2001,
	title = {Greedy function approximation: A gradient boosting machine.},
	volume = {29},
	issn = {0090-5364},
	doi = {10.1214/aos/1013203451},
	shorttitle = {Greedy function approximation},
	number = {5},
	journaltitle = {The Annals of Statistics},
	shortjournal = {Ann. Statist.},
	author = {Friedman, Jerome H.},
	date = {2001},
	file = {Full Text:/home/levantsi/Zotero/storage/9Q84642D/Friedman - 2001 - Greedy function approximation A gradient boosting.pdf:application/pdf},
}

@inproceedings{merrick_explanation_2020,
	title = {The Explanation Game: Explaining Machine Learning Models Using Shapley Values},
	isbn = {978-3-030-57321-8},
	doi = {10.1007/978-3-030-57321-8_2},
	series = {Lecture Notes in Computer Science},
    pages = {17--38},
	booktitle = {Machine Learning and Knowledge Extraction},
	publisher = {Springer International Publishing},
	author = {Merrick, Luke and Taly, Ankur},
	editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
	date = {2020},
	langid = {english},
	file = {Full Text PDF:/home/levantsi/Zotero/storage/4GMTLJZJ/Merrick and Taly - 2020 - The Explanation Game Explaining Machine Learning .pdf:application/pdf},
}


@article{airaksinen_development_2017,
	title = {Development and validation of a risk prediction model for work disability: Multicohort study},
	volume = {7},
	doi = {10.1038/s41598-017-13892-1},
	journaltitle = {Scientific Reports},
	shortjournal = {Scientific Reports},
	author = {Airaksinen, Jaakko and Jokela, Markus and Virtanen, Marianna and Oksanen, Tuula and Pentti, Jaana and Vahtera, Jussi and Koskenvuo, Markku and Kawachi, Ichiro and Batty, G. and Kivimäki, Mika},
	date = {2017},
	file = {Full Text PDF:/home/levantsi/Zotero/storage/8H628C7I/Airaksinen et al. - 2017 - Development and validation of a risk prediction mo.pdf:application/pdf},
}

@online{varis_aketurvakeskuksen_2018,
	title = {Eläketurvakeskuksen koneoppimiskokeilu – näin se tehtiin!},
	url = {https://www.etk.fi/blogit/elaketurvakeskuksen-koneoppimiskokeilu-nain-se-tehtiin/},
	titleaddon = {Eläketurvakeskus},
	author = {Varis, Jarno},
	urldate = {2022-10-17},
	date = {2018-04-17},
	langid = {finnish},
}

@inproceedings{saarela_work_2022,
	location = {Cham},
	title = {Work Disability Risk Prediction Using Machine Learning, Comparison of Two Methods},
	doi = {10.1007/978-3-031-14054-9_2},
	series = {Advances in Intelligent Systems and Computing},
	pages = {13--21},
	booktitle = {Proceedings of the {ICR}’22 International Conference on Innovations in Computing Research},
	publisher = {Springer International Publishing},
	author = {Saarela, Katja and Huhta-Koivisto, Vili and Nurminen, Jukka K.},
	editor = {Daimi, Kevin and Al Sadoon, Abeer},
	date = {2022},
	langid = {english},
	keywords = {Machine learning, Neural networks, {NLP}, {ULMFit}},
}


@article{perhoniemi_tyokyvyttomyyselakehakemusten_2020,
	title = {Työkyvyttömyyseläkehakemusten ja hylkäysosuuksien maakunnalliset erot},
	volume = {85},
	pages = {11},
	journaltitle = {Yhteiskuntapolitiikka},
	issn = {1458-6118},
	author = {Perhoniemi, Riku and Blomgren, Jenni and Laaksonen, Mikko},
	date = {2020},
	langid = {finnish},
}

@article{perhoniemi_determinants_2020,
	title = {Determinants of disability pension applications and awarded disability pensions in Finland, 2009 and 2014},
	volume = {48},
	issn = {1403-4948},
	doi = {10.1177/1403494819843778},
	pages = {172--180},
	number = {2},
	journaltitle = {Scandinavian Journal of Public Health},
	shortjournal = {Scand J Public Health},
	author = {Perhoniemi, Riku and Blomgren, Jenni and Laaksonen, Mikk},
	date = {2020},
	langid = {english},
	
}

@article{ding_model_2018,
	title = {Model Selection Techniques: An Overview},
	volume = {35},
	issn = {1558-0792},
	doi = {10.1109/MSP.2018.2867638},
	pages = {16--34},
	number = {6},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Ding, Jie and Tarokh, Vahid and Yang, Yuhong},
	date = {2018},
	note = {Conference Name: {IEEE} Signal Processing Magazine},
	keywords = {Analytical models, Big Data, Biological system modeling, Computational modeling, Data models, Machine learning, Predictive models},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\LEVANSI\\Zotero\\storage\\7EPQ324S\\Ding et al. - 2018 - Model Selection Techniques An Overview.pdf:application/pdf},
}

@article{elovainio_is_2021,
	title = {Is symptom connectivity really the most important issue in depression? Depression as a dynamic system of interconnected symptoms revisited},
	volume = {142},
	issn = {0022-3956},
	doi = {10.1016/j.jpsychires.2021.08.004},
	pages = {250--257},
	journaltitle = {Journal of Psychiatric Research},
	shortjournal = {Journal of Psychiatric Research},
	author = {Elovainio, Marko and Lipsanen, Jari and Pulkki-Råback, Laura and Suvisaari, Jaana and Hakulinen, Christian},
	date = {2021},
	langid = {english},
	keywords = {Causality, Depression, Network, Symptoms},
	file = {Full Text:C\:\\Users\\LEVANSI\\Zotero\\storage\\MINEUTTN\\Elovainio et al. - 2021 - Is symptom connectivity really the most important .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\LEVANSI\\Zotero\\storage\\FHTH4S75\\S0022395621005033.html:text/html},
}

@article{elovainio_network_2020,
	title = {A network approach to the analysis of psychosocial risk factors and their association with health},
	volume = {25},
	issn = {1359-1053},
	doi = {10.1177/1359105318765624},
	pages = {1587--1600},
	number = {10},
	journaltitle = {Journal of Health Psychology},
	author = {Elovainio, Marko and Hakulinen, Christian and Pulkki-Raback, Laura and Juonala, Markus and Raitakari, Olli T.},
	date = {2020},
	keywords = {515 Psychology, {ADULTHOOD}, {CARDIOVASCULAR} {RISK}, causality, {CHILDHOOD}, {DEPRESSIVE} {SYMPTOMS}, {DETERMINANTS}, epidemiology, {FOLLOW}-{UP}, {GENDER}-{DIFFERENCES}, health risks, {INEQUALITIES}, network, psychosocial, {SOCIOECONOMIC}-{STATUS}, {TEMPERAMENT}},
	file = {Accepted Version:C\:\\Users\\LEVANSI\\Zotero\\storage\\ENA7N8HB\\Elovainio et al. - 2020 - A network approach to the analysis of psychosocial.pdf:application/pdf},
}

@thesis{huhta-koivisto_work_2020,
	title = {Work disability risk prediction with machine learning},
	pagetotal = {62},
	institution = {Aalto-yliopisto},
	location = {Espoo},
	type = {diplomityö},
	author = {Huhta-Koivisto, Tero},
	date = {2020},
	langid = {english},
}
